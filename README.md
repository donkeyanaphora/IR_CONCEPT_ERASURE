# IR Concept Erasure

> **Goal:** Quantify how well projectionâ€‘based debiasing downâ€‘ranks userâ€‘defined â€œtriggerâ€ concepts in informationâ€‘retrieval tasks.

[![DatasetÂ Â TriggerIR](https://img.shields.io/badge/Dataset-TriggerIR-ff69b4?logo=huggingface)](https://huggingface.co/datasets/cwestnedge/TriggerIR)Â Â [![PythonÂ 3.13](https://img.shields.io/badge/python-3.13-blue)](#)Â Â [![MITÂ License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

---

## ğŸ“¦ Dataset

**TriggerIR on ğŸ¤—Â HuggingÂ Face**

```text
https://huggingface.co/datasets/cwestnedge/TriggerIR
```

*A creation script will be added once this repo is public.*

---

## ğŸ“ Metric

### TriggerÂ HitÂ RateÂ @Â k (THR\@k)

Counts how many of the topâ€‘*k* retrieved documents contain the queryâ€™s trigger concept, divided byÂ *k*.

$$
\text{THR@}k(q)=\frac{1}{k}\sum_{i=1}^{k}\mathbf{1}\bigl[d_{q,i}\,\text{ has trigger }q\bigr]
$$

* **Range:**Â 0Â â€“Â 1
* **Interpretation:**Â Lower after debiasing â‡’ trigger docs pushed down the ranking.
* **Code:**Â `labels_mat.sum(dim=1) / k`Â â†’ aggregated (mean, median, Wilcoxon).

---

## ğŸ“Š Results

<details open>
<summary><strong>Explicitâ€‘query</strong></summary>

#### Overall (THR\@10 across all triggers)

| metric       |  mean | median |
| ------------ | ----: | -----: |
| **baseline** | 0.840 |  0.900 |
| **debiased** | 0.484 |  0.500 |
| **diff**     | 0.356 |  0.300 |

#### WilcoxonÂ (baselineÂ >Â debiased)

|         Â WÂ  |    Â pâ€‘valueÂ  |
| ----------: | -----------: |
| 1.947Â Ã—Â 10â´ | 2.22Â Ã—Â 10â»Â³â´ |

#### Perâ€‘category

| category         | Î¼Â base | Î¼Â deb |  Î¼Â Î” | ËœÂ base | ËœÂ deb |  ËœÂ Î” |
| ---------------- | -----: | ----: | ---: | -----: | ----: | ---: |
| animal\_cruelty  |  0.840 | 0.450 | 0.39 |   0.90 |  0.40 | 0.40 |
| gore             |  0.873 | 0.610 | 0.26 |   0.90 |  0.55 | 0.30 |
| self\_harm       |  0.840 | 0.437 | 0.40 |   0.90 |  0.50 | 0.35 |
| sexual\_assault  |  0.828 | 0.448 | 0.38 |   0.80 |  0.40 | 0.40 |
| sexual\_content  |  0.830 | 0.510 | 0.32 |   0.80 |  0.60 | 0.30 |
| substance\_abuse |  0.937 | 0.437 | 0.50 |   1.00 |  0.40 | 0.50 |
| violence         |  0.661 | 0.500 | 0.16 |   0.70 |  0.50 | 0.20 |

![Explicit query viz](assets/explicit_query_viz.png)

</details>

<details>
<summary><strong>Neutralâ€‘query</strong></summary>

#### Overall

| metric       |  mean | median |
| ------------ | ----: | -----: |
| **baseline** | 0.423 |  0.400 |
| **debiased** | 0.241 |  0.200 |
| **diff**     | 0.182 |  0.100 |

#### WilcoxonÂ (baselineÂ >Â debiased)

|         Â WÂ  |    Â pâ€‘valueÂ  |
| ----------: | -----------: |
| 1.931Â Ã—Â 10â´ | 6.49Â Ã—Â 10â»Â³â´ |

#### Perâ€‘category

| category         | Î¼Â base | Î¼Â deb |  Î¼Â Î” | ËœÂ base | ËœÂ deb |  ËœÂ Î” |
| ---------------- | -----: | ----: | ---: | -----: | ----: | ---: |
| animal\_cruelty  |  0.433 | 0.197 | 0.24 |   0.40 |  0.20 | 0.20 |
| gore             |  0.493 | 0.323 | 0.17 |   0.50 |  0.30 | 0.10 |
| self\_harm       |  0.410 | 0.203 | 0.21 |   0.40 |  0.20 | 0.20 |
| sexual\_assault  |  0.414 | 0.248 | 0.17 |   0.40 |  0.20 | 0.10 |
| sexual\_content  |  0.473 | 0.283 | 0.19 |   0.50 |  0.25 | 0.20 |
| substance\_abuse |  0.267 | 0.123 | 0.14 |   0.25 |  0.05 | 0.10 |
| violence         |  0.500 | 0.356 | 0.14 |   0.50 |  0.40 | 0.10 |

![Neutral query viz](assets/neutral_query_viz.png)

</details>

---

## âš™ï¸ Reproduce

```bash
git clone https://github.com/your-handle/IR_Concept_Erasure.git
cd IR_Concept_Erasure
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
jupyter lab IRConceptErasure.ipynb   # or run as a script
```

---

## ğŸ—’ï¸ TODO

* [ ] Publish datasetâ€‘creation script
* [ ] Automate metric & figure generation
* [ ] Run ablations (layerâ€‘wise projection, alt embeddings)
